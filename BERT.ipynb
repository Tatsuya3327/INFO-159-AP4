{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JZFoTZ9Rd4bP"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/dbamman/nlp23/blob/master/AP/BERT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2AYm2QjD4WPA"
   },
   "source": [
    "BERT for binary or multiclass document classification using the [CLS] token as the document representation; trains a model (on `train.txt`), uses `dev.txt` for early stopping, and evaluates performance on `test.txt`.  Reports test accuracy with 95% confidence intervals.\n",
    "\n",
    "Before executing this notebook on Colab, make sure you're running on cuda (`Runtime > Change runtime type > GPU`) to make use of GPU speedups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "RXwcKMY44a04"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.28.1-py3-none-any.whl (7.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting huggingface-hub<1.0,>=0.11.0\n",
      "  Downloading huggingface_hub-0.14.1-py3-none-any.whl (224 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /Users/t.k/opt/anaconda3/lib/python3.8/site-packages (from transformers) (23.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/t.k/opt/anaconda3/lib/python3.8/site-packages (from transformers) (4.64.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/t.k/.local/lib/python3.8/site-packages (from transformers) (2021.10.8)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/t.k/opt/anaconda3/lib/python3.8/site-packages (from transformers) (1.23.5)\n",
      "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
      "  Downloading tokenizers-0.13.3-cp38-cp38-macosx_10_11_x86_64.whl (4.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests in /Users/t.k/opt/anaconda3/lib/python3.8/site-packages (from transformers) (2.28.1)\n",
      "Requirement already satisfied: filelock in /Users/t.k/opt/anaconda3/lib/python3.8/site-packages (from transformers) (3.9.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/t.k/opt/anaconda3/lib/python3.8/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/t.k/opt/anaconda3/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.4.0)\n",
      "Requirement already satisfied: fsspec in /Users/t.k/opt/anaconda3/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (2022.11.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/t.k/opt/anaconda3/lib/python3.8/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/t.k/opt/anaconda3/lib/python3.8/site-packages (from requests->transformers) (2022.12.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/t.k/opt/anaconda3/lib/python3.8/site-packages (from requests->transformers) (1.26.14)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /Users/t.k/opt/anaconda3/lib/python3.8/site-packages (from requests->transformers) (2.0.12)\n",
      "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
      "Successfully installed huggingface-hub-0.14.1 tokenizers-0.13.3 transformers-4.28.1\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "oeSgrDjF4WPC"
   },
   "outputs": [],
   "source": [
    "from transformers import BertModel, BertTokenizer\n",
    "import nltk\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import random\n",
    "from scipy.stats import norm\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F9qWkf0z4WPE"
   },
   "outputs": [],
   "source": [
    "# If you have your folder of data on your Google drive account, you can connect that here\n",
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "OcoE7WJQ6XRp"
   },
   "outputs": [],
   "source": [
    "# Change this to the directory with your data\n",
    "directory=\".\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "-ycKOkx34WPE"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Running on {}\".format(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "BuzjCRrG4WPF"
   },
   "outputs": [],
   "source": [
    "def read_labels(filename):\n",
    "    labels={}\n",
    "    with open(filename) as file:\n",
    "        for line in file:\n",
    "            cols = line.split(\"\\t\")\n",
    "            label = cols[2]\n",
    "            if label not in labels:\n",
    "                labels[label]=len(labels)\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "8XetKMAw4WPF"
   },
   "outputs": [],
   "source": [
    "def read_data(filename, labels, max_data_points=1000):\n",
    "  \n",
    "    data = []\n",
    "    data_labels = []\n",
    "    with open(filename) as file:\n",
    "        for line in file:\n",
    "            cols = line.split(\"\\t\")\n",
    "            label = cols[2]\n",
    "            text = cols[3]\n",
    "            \n",
    "            data.append(text)\n",
    "            data_labels.append(labels[label])\n",
    "            \n",
    "\n",
    "    # shuffle the data\n",
    "    tmp = list(zip(data, data_labels))\n",
    "    random.shuffle(tmp)\n",
    "    data, data_labels = zip(*tmp)\n",
    "    \n",
    "    if max_data_points is None:\n",
    "        return data, data_labels\n",
    "    \n",
    "    return data[:max_data_points], data_labels[:max_data_points]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "ZPfJqVmb4WPH"
   },
   "outputs": [],
   "source": [
    "labels=read_labels(\"%s/train.txt\" % directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "O-728X0b4WPI"
   },
   "outputs": [],
   "source": [
    "train_x, train_y=read_data(\"%s/train.txt\" % directory, labels, max_data_points=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "zQOE469I4WPI"
   },
   "outputs": [],
   "source": [
    "dev_x, dev_y=read_data(\"%s/dev.txt\" % directory, labels, max_data_points=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "vMpv6ZV54WPI"
   },
   "outputs": [],
   "source": [
    "test_x, test_y=read_data(\"%s/test.txt\" % directory, labels, max_data_points=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "gUKRjWsf4WPJ"
   },
   "outputs": [],
   "source": [
    "def evaluate(model, x, y):\n",
    "    model.eval()\n",
    "    corr = 0.\n",
    "    total = 0.\n",
    "    with torch.no_grad():\n",
    "        for x, y in zip(x, y):\n",
    "            y_preds=model.forward(x)\n",
    "            for idx, y_pred in enumerate(y_preds):\n",
    "                prediction=torch.argmax(y_pred)\n",
    "                if prediction == y[idx]:\n",
    "                    corr += 1.\n",
    "                total+=1                          \n",
    "    return corr/total, total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "xkUSuG794WPK"
   },
   "outputs": [],
   "source": [
    "class BERTClassifier(nn.Module):\n",
    "\n",
    "    def __init__(self, bert_model_name, params):\n",
    "        super().__init__()\n",
    "    \n",
    "        self.model_name=bert_model_name\n",
    "        self.tokenizer = BertTokenizer.from_pretrained(self.model_name, do_lower_case=params[\"doLowerCase\"], do_basic_tokenize=False)\n",
    "        self.bert = BertModel.from_pretrained(self.model_name)\n",
    "        \n",
    "        self.num_labels = params[\"label_length\"]\n",
    "\n",
    "        self.fc = nn.Linear(params[\"embedding_size\"], self.num_labels)\n",
    "\n",
    "    def get_batches(self, all_x, all_y, batch_size=32, max_toks=510):\n",
    "            \n",
    "        \"\"\" Get batches for input x, y data, with data tokenized according to the BERT tokenizer \n",
    "      (and limited to a maximum number of WordPiece tokens \"\"\"\n",
    "\n",
    "        batches_x=[]\n",
    "        batches_y=[]\n",
    "        \n",
    "        for i in range(0, len(all_x), batch_size):\n",
    "\n",
    "            current_batch=[]\n",
    "\n",
    "            x=all_x[i:i+batch_size]\n",
    "\n",
    "            batch_x = self.tokenizer(x, padding=True, truncation=True, return_tensors=\"pt\", max_length=max_toks)\n",
    "            batch_y=all_y[i:i+batch_size]\n",
    "\n",
    "            batches_x.append(batch_x.to(device))\n",
    "            batches_y.append(torch.LongTensor(batch_y).to(device))\n",
    "            \n",
    "        return batches_x, batches_y\n",
    "  \n",
    "\n",
    "    def forward(self, batch_x): \n",
    "    \n",
    "        bert_output = self.bert(input_ids=batch_x[\"input_ids\"],\n",
    "                         attention_mask=batch_x[\"attention_mask\"],\n",
    "                         token_type_ids=batch_x[\"token_type_ids\"],\n",
    "                         output_hidden_states=True)\n",
    "\n",
    "      # We're going to represent an entire document just by its [CLS] embedding (at position 0)\n",
    "      # And use the *last* layer output (layer -1)\n",
    "      # as a result of this choice, this embedding will be optimized for this purpose during the training process.\n",
    "      \n",
    "        bert_hidden_states = bert_output['hidden_states']\n",
    "\n",
    "        out = bert_hidden_states[-1][:,0,:]\n",
    "\n",
    "        out = self.fc(out)\n",
    "\n",
    "        return out.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "9mVrY9yv4WPL"
   },
   "outputs": [],
   "source": [
    "def confidence_intervals(accuracy, n, significance_level):\n",
    "    critical_value=(1-significance_level)/2\n",
    "    z_alpha=-1*norm.ppf(critical_value)\n",
    "    se=math.sqrt((accuracy*(1-accuracy))/n)\n",
    "    return accuracy-(se*z_alpha), accuracy+(se*z_alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "GiiXWwz94WPL"
   },
   "outputs": [],
   "source": [
    "def train(bert_model_name, model_filename, train_x, train_y, dev_x, dev_y, labels, embedding_size=768, doLowerCase=None):\n",
    "\n",
    "    bert_model = BERTClassifier(bert_model_name, params={\"label_length\": len(labels), \"doLowerCase\":doLowerCase, \"embedding_size\":embedding_size})\n",
    "    bert_model.to(device)\n",
    "\n",
    "    batch_x, batch_y = bert_model.get_batches(train_x, train_y)\n",
    "    dev_batch_x, dev_batch_y = bert_model.get_batches(dev_x, dev_y)\n",
    "\n",
    "    optimizer = torch.optim.Adam(bert_model.parameters(), lr=1e-5)\n",
    "    cross_entropy=nn.CrossEntropyLoss()\n",
    "\n",
    "    num_epochs=30\n",
    "    best_dev_acc = 0.\n",
    "    patience=5\n",
    "\n",
    "    best_epoch=0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        bert_model.train()\n",
    "\n",
    "        # Train\n",
    "        for x, y in zip(batch_x, batch_y):\n",
    "            y_pred = bert_model.forward(x)\n",
    "            loss = cross_entropy(y_pred.view(-1, bert_model.num_labels), y.view(-1))\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # Evaluate\n",
    "        dev_accuracy, _=evaluate(bert_model, dev_batch_x, dev_batch_y)\n",
    "        if epoch % 1 == 0:\n",
    "            print(\"Epoch %s, dev accuracy: %.3f\" % (epoch, dev_accuracy))\n",
    "            if dev_accuracy > best_dev_acc:\n",
    "                torch.save(bert_model.state_dict(), model_filename)\n",
    "                best_dev_acc = dev_accuracy\n",
    "                best_epoch=epoch\n",
    "        if epoch - best_epoch > patience:\n",
    "            print(\"No improvement in dev accuracy over %s epochs; stopping training\" % patience)\n",
    "            break\n",
    "\n",
    "    bert_model.load_state_dict(torch.load(model_filename))\n",
    "    print(\"\\nBest Performing Model achieves dev accuracy of : %.3f\" % (best_dev_acc))\n",
    "    return bert_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "Twbsysmd4WPM"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/bert_uncased_L-2_H-128_A-2 were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, dev accuracy: 0.760\n",
      "Epoch 1, dev accuracy: 0.760\n",
      "Epoch 2, dev accuracy: 0.760\n",
      "Epoch 3, dev accuracy: 0.760\n",
      "Epoch 4, dev accuracy: 0.760\n",
      "Epoch 5, dev accuracy: 0.760\n",
      "Epoch 6, dev accuracy: 0.760\n",
      "No improvement in dev accuracy over 5 epochs; stopping training\n",
      "\n",
      "Best Performing Model achieves dev accuracy of : 0.760\n"
     ]
    }
   ],
   "source": [
    "# small BERT -- can run on laptop\n",
    "bert_model_name=\"google/bert_uncased_L-2_H-128_A-2\"\n",
    "model_filename=\"mybert.model\"\n",
    "embedding_size=128\n",
    "doLowerCase=True\n",
    "\n",
    "# bert-base -- slow on laptop; better on Colab\n",
    "#bert_model_name=\"bert-base-cased\"\n",
    "#model_filename=\"mybert.model\"\n",
    "#embedding_size=768\n",
    "#doLowerCase=False\n",
    "\n",
    "model=train(bert_model_name, model_filename, train_x, train_y, dev_x, dev_y, labels, embedding_size=embedding_size, doLowerCase=doLowerCase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "UyImsx_C4WPN"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy for best dev model: 0.758, 95% CIs: [0.673 0.842]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_batch_x, test_batch_y = model.get_batches(test_x, test_y)\n",
    "accuracy, test_n=evaluate(model, test_batch_x, test_batch_y)\n",
    "\n",
    "lower, upper=confidence_intervals(accuracy, test_n, .95)\n",
    "print(\"Test accuracy for best dev model: %.3f, 95%% CIs: [%.3f %.3f]\\n\" % (accuracy, lower, upper))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "K4wL2Z8w4WPO"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdf\u001b[49m[\u001b[38;5;241m3\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
